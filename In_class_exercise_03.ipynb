{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In-class-exercise-03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VeerrajuP/Veerraju_INFO5731_Fall2021/blob/master/In_class_exercise_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaUT34VXdTHH"
      },
      "source": [
        "## The third In-class-exercise (9/29/2021, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehqmgHbIdTHI"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfDFSytrdTHI"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "bI2k03qSdTHJ",
        "outputId": "65b74af4-c150-46f9-97b7-f0410f04c6e9"
      },
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "The basic purpose of sentiment analysis from twitter data is to detect whether prople's tweets have positive or negatives feelings.\n",
        "\n",
        "In this work, both text classifications and text mining will be employed, with the text mining process bringing in data from twitter and text classification classifying the incoming data into smaller sections such as sentences, words, characters, punctuation and so on.\n",
        "\n",
        "The features to be extracted in this task are Uppercase words count, Numeric count, Special characters count, Stop words, Characters count, Word count, Sentence count.\n",
        "\n",
        "we can compare data for positive and negative attitudes. Finally we can determine if the overall sentiment of the tweets is favourable or negative by adding up all of the sentiment counts\n",
        "\n",
        "We can see the sentiments of people on twitter utilizing text mining and text classification in this way.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nPlease write you answer here:\\n\\nThe basic purpose of sentiment analysis from twitter data is to detect whether prople's tweets have positive or negatives feelings.\\n\\nIn this work, both text classifications and text mining will be employed, with the text mining process bringing in data from twitter and text classification classifying the incoming data into smaller sections such as sentences, words, characters, punctuation and so on.\\n\\nThe features to be extracted in this task are Uppercase words count, Numeric count, Special characters count, Stop words, Characters count, Word count, Sentence count.\\n\\nwe can compare data for positive and negative attitudes. Finally we can determine if the overall sentiment of the tweets is favourable or negative by adding up all of the sentiment counts\\n\\nWe can see the sentiments of people on twitter utilizing text mining and text classification in this way.\\n\\n\\n\\n\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBNvKe3KdTHJ"
      },
      "source": [
        "Question 2 (20 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5tvxLAOmOPjj",
        "outputId": "c7bca526-e66c-4d0b-c1bd-cb3cefe80ddf"
      },
      "source": [
        "#program to extract these features you discussed above. These are the few samples text data for the feature\n",
        "\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "\n",
        "con_key = \"Sl9QlYe2uIYFB4c56ht3suQpx\"\n",
        "con_secret = \"itmSoGGJBHAjnhcy0jZOyBHEEB9oYztj5mLBAa7yJm4tRAb2ai\"\n",
        "access_token = \"1438705493510344707-C3jtWFSrEjfyj0dtBY09lXUVsDL0oi\"\n",
        "access_token_secret = \"XEnNE1Mn6WupA0XnSV8aVNYXrV1k9no4iq6BMDZEOAV5d\"\n",
        "auth = tweepy.OAuthHandler(con_key, con_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
        "text_query = 'ACLU'\n",
        "max_tweets = 200\n",
        "tweets = tweepy.Cursor(api.search,q=text_query,lang='en', location = 'New york', since = '2021-02-01', until = '2021-09-29').items(max_tweets)\n",
        "tweets_list = [[tweet.text, tweet.created_at, tweet.id_str, tweet.user.name, tweet.user.screen_name, tweet.user.id_str, tweet.user.location, tweet.user.url, tweet.user.description, tweet.user.verified, tweet.user.followers_count, tweet.user.friends_count, tweet.user.favourites_count, tweet.user.statuses_count, tweet.user.listed_count, tweet.user.created_at, tweet.user.profile_image_url_https, tweet.user.default_profile, tweet.user.default_profile_image] for tweet in tweets]\n",
        "tweets_df = pd.DataFrame(tweets_list)\n",
        "tweets_df\n",
        "Tweets = pd.DataFrame()\n",
        "Tweets['Tweets'] = tweets_df[0]\n",
        "Tweets\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @NewLiberalsPod: It's fascinating how the s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @Patrick_Madden: ACLU Calls On Federal Pros...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @BRAINCURES: @GovAcctProj @AWhistleblowing ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@ACLU Wow, politics makes strange bedfellows</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @Patrick_Madden: ACLU Calls On Federal Pros...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>RT @nypost: ACLU apologizes for changing RBG q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>RT @Peace4all17: @KDansky @ACLU Is this like a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>RT @KGotsch: Congratulations to the many focus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>RT @ACLU: We need a pathway to citizenship for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>@JimBUWDawg @KDansky Start with the Gender Ide...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Tweets\n",
              "0    RT @NewLiberalsPod: It's fascinating how the s...\n",
              "1    RT @Patrick_Madden: ACLU Calls On Federal Pros...\n",
              "2    RT @BRAINCURES: @GovAcctProj @AWhistleblowing ...\n",
              "3         @ACLU Wow, politics makes strange bedfellows\n",
              "4    RT @Patrick_Madden: ACLU Calls On Federal Pros...\n",
              "..                                                 ...\n",
              "195  RT @nypost: ACLU apologizes for changing RBG q...\n",
              "196  RT @Peace4all17: @KDansky @ACLU Is this like a...\n",
              "197  RT @KGotsch: Congratulations to the many focus...\n",
              "198  RT @ACLU: We need a pathway to citizenship for...\n",
              "199  @JimBUWDawg @KDansky Start with the Gender Ide...\n",
              "\n",
              "[200 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s80Gh7-BOSC8",
        "outputId": "fb77fc1f-f8d6-4a9c-dbb6-3b966707ef68"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu2w89YoOaoZ",
        "outputId": "e9c2291d-0956-46c3-aaf3-bed9b5b9dc94"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "IKxMsFA-OiBC",
        "outputId": "318fa623-ee1a-417e-b249-d52e43214499"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import *\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "Tweet1 = pd.DataFrame()\n",
        "Tweet1['Tweets'] = tweets_df[0]\n",
        "Tweet = Tweets\n",
        "Tweet1['Tweets'] = Tweet1['Tweets'].apply(sent_tokenize)\n",
        "Tweet['Sen_Count'] = Tweet1['Tweets'].apply(len)\n",
        "Tweet['Wd_Count'] = Tweet['Tweets'].apply(lambda x: len(str(x).split(\" \")))\n",
        "Tweet['Char_Count'] = Tweet['Tweets'].str.len()\n",
        "\n",
        "def avg_word(sentence):\n",
        "  words = sentence.split()\n",
        "  return (sum(len(word) for word in words)/len(words))\n",
        "\n",
        "Tweet['Avg_Word'] = Tweet['Tweets'].apply(lambda x: avg_word(x))\n",
        "stop = stopwords.words('english')\n",
        "Tweet['Stopwords'] = Tweet['Tweets'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
        "Special_Characters = '[@_!#$%^&*()<>?/\\|}{~:]'\n",
        "SC_Tuple = tuple(Special_Characters)\n",
        "Tweet['Special_Characters_Count'] = Tweet['Tweets'].apply(lambda x: len([x for x in x.split() if x.startswith(SC_Tuple)]))\n",
        "Tweet['Numerics_Count'] = Tweet['Tweets'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
        "Tweet['Upper_Count'] = Tweet['Tweets'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
        "Tweet"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweets</th>\n",
              "      <th>Sen_Count</th>\n",
              "      <th>Wd_Count</th>\n",
              "      <th>Char_Count</th>\n",
              "      <th>Avg_Word</th>\n",
              "      <th>Stopwords</th>\n",
              "      <th>Special_Characters_Count</th>\n",
              "      <th>Numerics_Count</th>\n",
              "      <th>Upper_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @NewLiberalsPod: It's fascinating how the s...</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>140</td>\n",
              "      <td>5.086957</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @Patrick_Madden: ACLU Calls On Federal Pros...</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>140</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @BRAINCURES: @GovAcctProj @AWhistleblowing ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>140</td>\n",
              "      <td>11.818182</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@ACLU Wow, politics makes strange bedfellows</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>44</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @Patrick_Madden: ACLU Calls On Federal Pros...</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>140</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>RT @nypost: ACLU apologizes for changing RBG q...</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>126</td>\n",
              "      <td>7.466667</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>RT @Peace4all17: @KDansky @ACLU Is this like a...</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>140</td>\n",
              "      <td>5.043478</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>RT @KGotsch: Congratulations to the many focus...</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>140</td>\n",
              "      <td>6.421053</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>RT @ACLU: We need a pathway to citizenship for...</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>128</td>\n",
              "      <td>5.736842</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>@JimBUWDawg @KDansky Start with the Gender Ide...</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>83</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Tweets  ...  Upper_Count\n",
              "0    RT @NewLiberalsPod: It's fascinating how the s...  ...            1\n",
              "1    RT @Patrick_Madden: ACLU Calls On Federal Pros...  ...            2\n",
              "2    RT @BRAINCURES: @GovAcctProj @AWhistleblowing ...  ...            4\n",
              "3         @ACLU Wow, politics makes strange bedfellows  ...            1\n",
              "4    RT @Patrick_Madden: ACLU Calls On Federal Pros...  ...            2\n",
              "..                                                 ...  ...          ...\n",
              "195  RT @nypost: ACLU apologizes for changing RBG q...  ...            3\n",
              "196  RT @Peace4all17: @KDansky @ACLU Is this like a...  ...            2\n",
              "197  RT @KGotsch: Congratulations to the many focus...  ...            1\n",
              "198  RT @ACLU: We need a pathway to citizenship for...  ...            2\n",
              "199  @JimBUWDawg @KDansky Start with the Gender Ide...  ...            1\n",
              "\n",
              "[200 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "2XCLRnLHPBR2",
        "outputId": "11ab1c39-e82e-4de6-f80d-d5277e4fe7ac"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "Tweet2 = pd.DataFrame()\n",
        "Tweet2['Tweets'] = Tweet['Tweets'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "Tweet2['Tweets'] = Tweet2['Tweets'].str.replace('[^\\w\\s]','')\n",
        "Tweet2['Tweets'] = Tweet2['Tweets'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "common = pd.Series(' '.join(Tweet2['Tweets']).split()).value_counts()[:10]\n",
        "Tweet2['Tweets'] = Tweet2['Tweets'].apply(lambda x: \" \".join(x for x in x.split() if x not in common))\n",
        "rare = pd.Series(' '.join(Tweet2['Tweets']).split()).value_counts()[-10:]\n",
        "Tweet2['Tweets'] = Tweet2['Tweets'].apply(lambda x: \" \".join(x for x in x.split() if x not in rare))\n",
        "\n",
        "from textblob import TextBlob\n",
        "Tweet2['Tweets'][:5].apply(lambda x: str(TextBlob(x).correct()))\n",
        "\n",
        "TextBlob(Tweet2['Tweets'][1]).words\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "Tweet2['Tweets'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "\n",
        "from textblob import Word\n",
        "Tweet2['Tweets'] = Tweet2['Tweets'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "Tweet2\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>newliberalspod century</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>patrick_madden call federal prosecutor investi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>braincures govacctproj awhistleblowing whistle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wow politics make strange bedfellow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>patrick_madden call federal prosecutor investi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>nypost apologizes changing rbg quote delete wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>peace4all17 kdansky like terf thing bc used cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>kgotsch congratulation many focused determined...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>need pathway citizenship immigrant call americ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>jimbuwdawg kdansky start gender identity ideol...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Tweets\n",
              "0                               newliberalspod century\n",
              "1    patrick_madden call federal prosecutor investi...\n",
              "2    braincures govacctproj awhistleblowing whistle...\n",
              "3                  wow politics make strange bedfellow\n",
              "4    patrick_madden call federal prosecutor investi...\n",
              "..                                                 ...\n",
              "195  nypost apologizes changing rbg quote delete wo...\n",
              "196  peace4all17 kdansky like terf thing bc used cl...\n",
              "197  kgotsch congratulation many focused determined...\n",
              "198  need pathway citizenship immigrant call americ...\n",
              "199  jimbuwdawg kdansky start gender identity ideol...\n",
              "\n",
              "[200 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9-KO89ZdTHK"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\" Select the most important features you extracted above, rank the features based on their importance in the descending order. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HPZBqsMZdTHK",
        "outputId": "255238ae-8e06-4241-a6a8-f6780dcb2ede"
      },
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "def sentiment_calc(text):\n",
        "    try:\n",
        "        return TextBlob(text).sentiment\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "#We added the outcome to data\n",
        "Tweet2['Polarity_Subjectivity'] = Tweet2['Tweets'].apply(sentiment_calc)\n",
        "Tweet2['Polarity'] = Tweet2['Polarity_Subjectivity'].apply(lambda x: x[0])\n",
        "\n",
        "def sentiment(Polarity):\n",
        "  if Polarity>0:\n",
        "    return '+ve'\n",
        "  else:\n",
        "    return '-ve'\n",
        "#polarity is negative sentiment is filtered as negative and viceversa\n",
        "\n",
        "Tweet2['Sentiment'] = Tweet2['Polarity'].apply(sentiment)\n",
        "Tweet2\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweets</th>\n",
              "      <th>Polarity_Subjectivity</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>newliberalspod century</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>patrick_madden call federal prosecutor investi...</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>braincures govacctproj awhistleblowing whistle...</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wow politics make strange bedfellow</td>\n",
              "      <td>(0.025, 0.575)</td>\n",
              "      <td>0.025</td>\n",
              "      <td>+ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>patrick_madden call federal prosecutor investi...</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>nypost apologizes changing rbg quote delete wo...</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>peace4all17 kdansky like terf thing bc used cl...</td>\n",
              "      <td>(0.10000000000000002, 0.3833333333333333)</td>\n",
              "      <td>0.100</td>\n",
              "      <td>+ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>kgotsch congratulation many focused determined...</td>\n",
              "      <td>(0.5, 0.5)</td>\n",
              "      <td>0.500</td>\n",
              "      <td>+ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>need pathway citizenship immigrant call americ...</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>jimbuwdawg kdansky start gender identity ideol...</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-ve</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Tweets  ... Sentiment\n",
              "0                               newliberalspod century  ...       -ve\n",
              "1    patrick_madden call federal prosecutor investi...  ...       -ve\n",
              "2    braincures govacctproj awhistleblowing whistle...  ...       -ve\n",
              "3                  wow politics make strange bedfellow  ...       +ve\n",
              "4    patrick_madden call federal prosecutor investi...  ...       -ve\n",
              "..                                                 ...  ...       ...\n",
              "195  nypost apologizes changing rbg quote delete wo...  ...       -ve\n",
              "196  peace4all17 kdansky like terf thing bc used cl...  ...       +ve\n",
              "197  kgotsch congratulation many focused determined...  ...       +ve\n",
              "198  need pathway citizenship immigrant call americ...  ...       -ve\n",
              "199  jimbuwdawg kdansky start gender identity ideol...  ...       -ve\n",
              "\n",
              "[200 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}