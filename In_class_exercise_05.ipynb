{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_05-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VeerrajuP/Veerraju_INFO5731_Fall2021/blob/master/In_class_exercise_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHjLe-Wc_A3y"
      },
      "source": [
        "# **The fifth in-class-exercise (40 points in total, 11/11/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCboG92n_A31"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "VYaaqYFA_A31",
        "outputId": "8e43d0cb-290c-4e1d-9e2f-b984f42df862"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-02175bf3-a6e3-422f-9dcf-f69c867cd644\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-02175bf3-a6e3-422f-9dcf-f69c867cd644\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving stsa-test.txt to stsa-test.txt\n",
            "Saving stsa-train.txt to stsa-train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7kkN9Uz05N6",
        "outputId": "1c98585e-f9d8-4139-9d05-42565f3cd435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "test = pd.read_csv(r'stsa-test.txt',sep = 'delimiter=',header= None,names=['Reviews'])\n",
        "test[['Sentiment','Reviews']] = test[\"Reviews\"].str.split(\" \", 1, expand=True)\n",
        "test"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>culkin exudes none of the charm or charisma th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>if your senses have n't been dulled by slasher...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>any one episode of the sopranos would send thi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>as conceived by mr. schaeffer , christopher an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>enough similarities to gymkata and howie long ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816</th>\n",
              "      <td>an often-deadly boring , strange reading of a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1818</th>\n",
              "      <td>safe conduct , however ambitious and well-inte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1819</th>\n",
              "      <td>a film made with as little wit , interest , an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1820</th>\n",
              "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1821 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Reviews Sentiment\n",
              "0     culkin exudes none of the charm or charisma th...         0\n",
              "1     if your senses have n't been dulled by slasher...         1\n",
              "2     any one episode of the sopranos would send thi...         0\n",
              "3     as conceived by mr. schaeffer , christopher an...         0\n",
              "4     enough similarities to gymkata and howie long ...         0\n",
              "...                                                 ...       ...\n",
              "1816  an often-deadly boring , strange reading of a ...         0\n",
              "1817  the problem with concept films is that if the ...         0\n",
              "1818  safe conduct , however ambitious and well-inte...         0\n",
              "1819  a film made with as little wit , interest , an...         0\n",
              "1820  but here 's the real damn : it is n't funny , ...         0\n",
              "\n",
              "[1821 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "i6rptluIBuGc",
        "outputId": "39238c6b-5e90-49c5-bdab-21d6f7b46d85"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv(r'stsa-train.txt',sep = 'delimiter=',header= None,names=['Reviews'])\n",
        "train[['Sentiment','Reviews']] = train[\"Reviews\"].str.split(\" \", 1,expand=True)\n",
        "train"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a preposterous , prurient whodunit .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>they are what makes it worth the trip to the t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chan 's stunts are limited and so embellished ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>an average kid-empowerment fantasy with slight...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>instead of making his own style , director mar...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6928</th>\n",
              "      <td>it uses some of the figures from the real-life...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6929</th>\n",
              "      <td>for casual moviegoers who stumble into rules e...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6930</th>\n",
              "      <td>it could have been something special , but two...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6931</th>\n",
              "      <td>affable if not timeless , like mike raises som...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6932</th>\n",
              "      <td>slap her - she 's not funny !</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6933 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Reviews Sentiment\n",
              "0                  a preposterous , prurient whodunit .         0\n",
              "1     they are what makes it worth the trip to the t...         1\n",
              "2     chan 's stunts are limited and so embellished ...         0\n",
              "3     an average kid-empowerment fantasy with slight...         1\n",
              "4     instead of making his own style , director mar...         0\n",
              "...                                                 ...       ...\n",
              "6928  it uses some of the figures from the real-life...         1\n",
              "6929  for casual moviegoers who stumble into rules e...         0\n",
              "6930  it could have been something special , but two...         0\n",
              "6931  affable if not timeless , like mike raises som...         1\n",
              "6932                      slap her - she 's not funny !         0\n",
              "\n",
              "[6933 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlMMCq3fCHiB",
        "outputId": "a175dfc2-2752-4ab1-ca0b-e617dd472c5a"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stopword=nltk.corpus.stopwords.words('english')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wdnlt= WordNetLemmatizer()\n",
        "print( )\n",
        "\n",
        "def cleaning(words):\n",
        "  words=\"\".join([word.lower() for word in words if word not in string.punctuation])\n",
        "  words = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", words)\n",
        "  tokens = re.split('\\W+',words)\n",
        "  words = [wl.lemmatize(word) for word in tokens if word not in stopword]\n",
        "  return words\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vect = TfidfVectorizer(analyzer = cleaning)\n",
        "a_vect = vect.fit_transform(train['Reviews'])\n",
        "print(a_vect.shape)\n",
        "a_vect_df=pd.DataFrame(a_vect.toarray())\n",
        "a_vect_df.columns=vect.get_feature_names()\n",
        "a_vect_df.head()\n",
        "a_test_vect = vect.transform(test['Reviews'])\n",
        "print(a_test_vect.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "\n",
            "(6920, 13343)\n",
            "(1821, 13343)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACLOhWIpD3A4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
        "a_train, a_test, b_train, b_test = train_test_split(a_vect_df, train['Sentiment'].values, test_size=0.2, random_state=42)\n",
        "model_mul = mul.fit(a_train,b_train)\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKmuPf9nD4CO",
        "outputId": "c040d6ce-6869-4cdb-f96d-270bceda41e3"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "mulnm = MultinomialNB()\n",
        "model_mulnm = mulnm.fit(a_train,b_train)\n",
        "b_pred_mulnm = model_mulnm.predict(a_test)\n",
        "print('Accuracy %s' % accuracy_score(b_pred_mulnm,b_test))\n",
        "print(classification_report(b_test,b_pred_mulnm))\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(mulnm, a_test, b_test, cv=10)\n",
        "print(\"using multinomialNB\",scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.7955202312138728\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.70      0.77       671\n",
            "           1       0.76      0.88      0.82       713\n",
            "\n",
            "    accuracy                           0.80      1384\n",
            "   macro avg       0.80      0.79      0.79      1384\n",
            "weighted avg       0.80      0.80      0.79      1384\n",
            "\n",
            "using multinomialNB 0.7247054530288813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pJe9tLsD8td",
        "outputId": "852f8468-c4a3-446c-e38a-82f782063a08"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "linsvc = LinearSVC()\n",
        "model_linsvc = lin.fit(a_train,b_train)\n",
        "b_pred_linsvc = model_linsvc.predict(a_test)\n",
        "print('Accuracy %s' % accuracy_score(b_pred_lin,b_test))\n",
        "print(classification_report(b_test,b_pred_linsvc))\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(lin, a_test, b_test, cv=10)\n",
        "print(\"using linearSVC\",scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.791907514450867\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.75      0.78       671\n",
            "           1       0.78      0.83      0.80       713\n",
            "\n",
            "    accuracy                           0.79      1384\n",
            "   macro avg       0.79      0.79      0.79      1384\n",
            "weighted avg       0.79      0.79      0.79      1384\n",
            "\n",
            "using linearSVC 0.7348034615785632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q16cCQnERbP",
        "outputId": "1fff73fc-c563-4a1a-ea0e-057f17131eed"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knecfr = KNeighborsClassifier(n_neighbors=5,n_jobs=-1)\n",
        "model_knecfr = knecfr.fit(a_train,b_train)\n",
        "b_pred_knecfr = model_knecfr.predict(x_test)\n",
        "print('Accuracy %s' % accuracy_score(b_pred_knecfr,b_test))\n",
        "print(classification_report(b_test,b_pred_knecfr))\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(knecfr, a_test, b_test, cv=10)\n",
        "print(\"using knecfr\",scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.7398843930635838\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.70      0.72       671\n",
            "           1       0.74      0.77      0.75       713\n",
            "\n",
            "    accuracy                           0.74      1384\n",
            "   macro avg       0.74      0.74      0.74      1384\n",
            "weighted avg       0.74      0.74      0.74      1384\n",
            "\n",
            "using knecfr 0.6675737670732979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXmU5vkiFOEj",
        "outputId": "eef919de-5167-49d7-ad15-5d75218ea154"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dectcfr = DecisionTreeClassifier()\n",
        "model_dectcfr = dectcfr.fit(a_train,b_train)\n",
        "b_pred_dectcfr = model_dectcfr.predict(a_test)\n",
        "print('Accuracy %s' % accuracy_score(b_pred_dectcfr,b_test))\n",
        "print(classification_report(b_test,b_pred_dectcfr))\n",
        "scores = cross_val_score(dectcfr, a_test, b_test, cv=10)\n",
        "print(\"using decision trees\",scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.6596820809248555\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.61      0.63       671\n",
            "           1       0.66      0.71      0.68       713\n",
            "\n",
            "    accuracy                           0.66      1384\n",
            "   macro avg       0.66      0.66      0.66      1384\n",
            "weighted avg       0.66      0.66      0.66      1384\n",
            "\n",
            "using decision trees 0.6090397247419456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur7pO0YEGzwk",
        "outputId": "b11acfa0-2d53-4f37-8db2-b50aa832b958"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "ranfcfr = RandomForestClassifier()\n",
        "model_ranfcfr = ranfcfr.fit(a_train,b_train)\n",
        "b_pred_ranfcfr = model_ranfcfr.predict(a_test)\n",
        "print('Accuracy %s' % accuracy_score(b_pred_ran,b_test))\n",
        "print(classification_report(b_test,b_pred_ran))\n",
        "scores = cross_val_score(ranfcfr, a_test, b_test, cv=10)\n",
        "print(\"using random forest\",scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.7384393063583815\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.66      0.71       671\n",
            "           1       0.72      0.81      0.76       713\n",
            "\n",
            "    accuracy                           0.74      1384\n",
            "   macro avg       0.74      0.74      0.74      1384\n",
            "weighted avg       0.74      0.74      0.74      1384\n",
            "\n",
            "using random forest 0.6820196017099363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rKEC-4UHCBT",
        "outputId": "a4936f12-552a-4cc3-ed68-95e6c4c73500"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgbcfr = XGBClassifier()\n",
        "model_xgbcfr = xgbcfr.fit(a_train,b_train)\n",
        "b_pred_xgbcfr = model_xgbcfr.predict(b_test)\n",
        "print('Accuracy %s' % accuracy_score(b_pred_xgbcfr,b_test))\n",
        "print(classification_report(b_test,b_pred_xgbcfr))\n",
        "scores = cross_val_score(xgbcfr, a_test, b_test, cv=10)\n",
        "print(\"using xgbxfr\",scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.6445086705202312\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.40      0.52       671\n",
            "           1       0.61      0.88      0.72       713\n",
            "\n",
            "    accuracy                           0.64      1384\n",
            "   macro avg       0.68      0.64      0.62      1384\n",
            "weighted avg       0.68      0.64      0.62      1384\n",
            "\n",
            "using xgb 0.6184704410384736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2Fr0ZjEHIsJ",
        "outputId": "4bc4da30-af23-4a20-ec2d-470b72821ca3"
      },
      "source": [
        "test_predict_mulnm = model_mulnm.predict((a_test_vector))\n",
        "print('Accuracy %s' % accuracy_score(test_predict_mulnm,test['Sentiment']))\n",
        "print(classification_report(test_predict_mulnm,test['Sentiment']))\n",
        "test_predict_linsvc = model_linsvc.predict(a_test_vector)\n",
        "print('Accuracy %s' % accuracy_score(test_predict_linsvc,test['Sentiment']))\n",
        "print(classification_report(test_predict_linsvc,test['Sentiment']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.7946183415705657\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.87      0.77       730\n",
            "           1       0.89      0.75      0.81      1091\n",
            "\n",
            "    accuracy                           0.79      1821\n",
            "   macro avg       0.79      0.81      0.79      1821\n",
            "weighted avg       0.81      0.79      0.80      1821\n",
            "\n",
            "Accuracy 0.7891268533772653\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       844\n",
            "           1       0.83      0.77      0.80       977\n",
            "\n",
            "    accuracy                           0.79      1821\n",
            "   macro avg       0.79      0.79      0.79      1821\n",
            "weighted avg       0.79      0.79      0.79      1821\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaHToNQz_A32"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "Apply the listed clustering methods to the dataset:\n",
        "\n",
        "K means, \n",
        "DBSCAN,\n",
        "Hierarchical clustering. \n",
        "\n",
        "You can refer to of the codes from  the follwing link below. \n",
        "https://www.kaggle.com/karthik3890/text-clustering "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "1MuGPO4z_A33",
        "outputId": "10293086-de51-4ece-d738-40411adc4f1f"
      },
      "source": [
        "#Write your code here.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4cbe4fe1-115c-40e4-ac88-d158aa108298\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4cbe4fe1-115c-40e4-ac88-d158aa108298\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Amazon_Unlocked_Mobile.csv to Amazon_Unlocked_Mobile.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUhUjFwj2AZc"
      },
      "source": [
        "import pandas as pd\n",
        "amazon=pd.read_csv(\"Amazon_Unlocked_Mobile.csv\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pJTat6I8ACN"
      },
      "source": [
        "amazon = amazon[amazon['Reviews'].notnull()].head(10000)\n",
        "amazon['after_punct'] = amazon['Reviews'].str.replace('[^\\w\\s].#','')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLG_PEhm8Fii",
        "outputId": "ca39dee9-d0d0-4026-fb4a-e83b554f00ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "amazon['after_stopwords'] =amazon['after_punct'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMapAtwFTz5H",
        "outputId": "03815c93-4c4a-4196-f605-0557fae38598"
      },
      "source": [
        "amazon['after_num']=amazon['after_stopwords'].str.replace('[0-9]','')\n",
        "amazon['after_lc'] =amazon['after_num'].apply(lambda a: \" \".join(a.lower() for a in a.split()))\n",
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "amazon['after_sm']=amazon['after_lc'].apply(lambda a: \" \".join([st.stem(word) for word in a.split()]))\n",
        "from textblob import Word\n",
        "amazon['clnd'] = amazon['after_sm'].apply(lambda a: \" \".join([Word(word).lemmatize() for word in a.split()]))\n",
        "amazon['clnd']"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        i feel lucki found use (phone u & use hard all...\n",
              "1        nice phone, nice grade pantach revue. veri cle...\n",
              "2                                                veri plea\n",
              "3          it work good goe slow sometim good phone i love\n",
              "4        great phone replac lost phone. the thing volum...\n",
              "                               ...                        \n",
              "9996     first iphon receiv great condition. rival bran...\n",
              "9997     should black color white took white color sent...\n",
              "9998     the phone not unlock i receiv it. i tri sever ...\n",
              "9999     it nice phone, like it.it like brand app avail...\n",
              "10000    futur buy client compani person call himself, ...\n",
              "Name: clnd, Length: 10000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeV12aUgURXl",
        "outputId": "4a3c5820-a321-4f64-bbf7-52a3cf5dcef8"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vec = TfidfVectorizer()\n",
        "tfidf = vec.fit_transform(amazon['clnd'].values)\n",
        "tfidf.shape\n",
        "print( )\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiOryU29_xll"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "model_km = KMeans(n_clusters = 15, n_jobs = -1,random_state=200)\n",
        "model_km.fit(tfidf)\n",
        "\n",
        "labels_km = model_km.labels_\n",
        "cluster_center_km=model_km.cluster_centers_\n",
        "terms = vector.get_feature_names()\n",
        "terms[1:5]\n",
        "amazon['Label'] = model_km.labels_\n",
        "amazon\n",
        "\n",
        "amazon.groupby(['Label'])['clnd'].count()\n",
        "print( )\n",
        "\n",
        "print(\"Top terms per cluster:\")\n",
        "centroids = model_km.cluster_centers_.argsort()[:, ::-1]\n",
        "for i in range(1,15):\n",
        "    print(\"Cluster %d:\" % i, end='')\n",
        "    for ind in centroids[i, :15]:\n",
        "        print(' %s' % terms[ind], end='')\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uk-F18VtXAkQ",
        "outputId": "841d538c-2002-43e7-b8cf-7a8220d417cb"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "import gensim\n",
        "sentences=[]\n",
        "for s in amazon['clnd'].values:\n",
        "    sentences.append(s.split())\n",
        "wordvector_model=gensim.models.Word2Vec(sentences,size=3000, workers=8)\n",
        "\n",
        "import numpy as np\n",
        "vectors = [];\n",
        "for s in sentences:\n",
        "    s_v = np.zeros(300)\n",
        "    count =0;\n",
        "    for word in s:\n",
        "        try:\n",
        "            vector = wordvector_model.wv[word]\n",
        "            s_v += vector\n",
        "            count += 1\n",
        "        except:\n",
        "            pass\n",
        "    s_v /= count\n",
        "    vectors.append(s_v)\n",
        "vectors = np.array(vectors)\n",
        "vectors = np.nan_to_num(vectors)\n",
        "vectors.shape\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "pts = 2 * 300\n",
        "model_dbscan = DBSCAN(eps = 4, min_samples = pts, n_jobs=-1)\n",
        "model_dbscan.fit(vectors)\n",
        "amazon['AVG Label'] = model_dbscan.labels_\n",
        "amazon"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "      <th>after_punct</th>\n",
              "      <th>after_stopwords</th>\n",
              "      <th>after_num</th>\n",
              "      <th>after_lc</th>\n",
              "      <th>after_sm</th>\n",
              "      <th>clnd</th>\n",
              "      <th>AVG Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucky found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucki found use (phone us &amp; use hard al...</td>\n",
              "      <td>i feel lucki found use (phone u &amp; use hard all...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>very pleased</td>\n",
              "      <td>veri pleas</td>\n",
              "      <td>veri plea</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>it works good goes slow sometimes good phone i...</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>great phone replace lost phone. the thing volu...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Apple iPhone 4 8GB, Unlocked (Black)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>122.00</td>\n",
              "      <td>2</td>\n",
              "      <td>First of all the Iphone receive was in great c...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>First of all the Iphone receive was in great c...</td>\n",
              "      <td>First Iphone receive great condition. Rival br...</td>\n",
              "      <td>First Iphone receive great condition. Rival br...</td>\n",
              "      <td>first iphone receive great condition. rival br...</td>\n",
              "      <td>first iphon receiv great condition. rival bran...</td>\n",
              "      <td>first iphon receiv great condition. rival bran...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>Apple iPhone 4 8GB, Unlocked (Black)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>122.00</td>\n",
              "      <td>4</td>\n",
              "      <td>Should of been black color but only had white ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Should of been black color but only had white ...</td>\n",
              "      <td>Should black color white took white color sent...</td>\n",
              "      <td>Should black color white took white color sent...</td>\n",
              "      <td>should black color white took white color sent...</td>\n",
              "      <td>should black color white took white color sent...</td>\n",
              "      <td>should black color white took white color sent...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Apple iPhone 4 8GB, Unlocked (Black)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>122.00</td>\n",
              "      <td>1</td>\n",
              "      <td>The phone was NOT unlocked when I received it....</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The phone was NOT unlocked when I received it....</td>\n",
              "      <td>The phone NOT unlocked I received it. I tried ...</td>\n",
              "      <td>The phone NOT unlocked I received it. I tried ...</td>\n",
              "      <td>the phone not unlocked i received it. i tried ...</td>\n",
              "      <td>the phone not unlock i receiv it. i tri sever ...</td>\n",
              "      <td>the phone not unlock i receiv it. i tri sever ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>Apple iPhone 4 8GB, Unlocked (Black)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>122.00</td>\n",
              "      <td>4</td>\n",
              "      <td>Its a nice phone, i like it.It like because of...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Its a nice phone, i like it.It like because of...</td>\n",
              "      <td>Its nice phone, like it.It like brand apps ava...</td>\n",
              "      <td>Its nice phone, like it.It like brand apps ava...</td>\n",
              "      <td>its nice phone, like it.it like brand apps ava...</td>\n",
              "      <td>it nice phone, like it.it like brand app avail...</td>\n",
              "      <td>it nice phone, like it.it like brand app avail...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>Apple iPhone 4 8GB, Unlocked (Black)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>122.00</td>\n",
              "      <td>1</td>\n",
              "      <td>Futures buying clients this company or person ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Futures buying clients this company or person ...</td>\n",
              "      <td>Futures buying clients company person calls hi...</td>\n",
              "      <td>Futures buying clients company person calls hi...</td>\n",
              "      <td>futures buying clients company person calls hi...</td>\n",
              "      <td>futur buy client compani person call himself, ...</td>\n",
              "      <td>futur buy client compani person call himself, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Product Name  ... AVG Label\n",
              "0      \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...         0\n",
              "1      \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...         0\n",
              "2      \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...         0\n",
              "3      \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...         0\n",
              "4      \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...         0\n",
              "...                                                  ...  ...       ...\n",
              "9996                Apple iPhone 4 8GB, Unlocked (Black)  ...         0\n",
              "9997                Apple iPhone 4 8GB, Unlocked (Black)  ...         0\n",
              "9998                Apple iPhone 4 8GB, Unlocked (Black)  ...         0\n",
              "9999                Apple iPhone 4 8GB, Unlocked (Black)  ...         0\n",
              "10000               Apple iPhone 4 8GB, Unlocked (Black)  ...         0\n",
              "\n",
              "[10000 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiR7r70fAj5X"
      },
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "c = AgglomerativeClustering(n_clusters=17, affinity='euclidean', linkage='ward')  \n",
        "Agg=c.fit_predict(vectors)\n",
        "\n",
        "amazon['AVG Label'] = c.labels_\n",
        "amazon.head(15)\n",
        "amazon.groupby(['AVG Label'])['clnd'].count()\n",
        "print( )\n",
        "\n",
        "for k in range(15):\n",
        "    print(\"Example of 10 reviews assigned to cluster \", k)\n",
        "    print(\"-\" * 100)\n",
        "    print(amazon.iloc[amazon.groupby(['AVG Label']).groups[k][0]]['clnd'])\n",
        "    print('\\n')\n",
        "    print(amazon.iloc[amazon.groupby(['AVG Label']).groups[k][1]]['clnd'])\n",
        "    print('\\n')\n",
        "    print(\"_\" * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd4eb5gf_A33"
      },
      "source": [
        "In one paragraph, please compare K means, DBSCAN and Hierarchical clustering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEmqC-dT_A33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "7e96251d-7820-45b6-b1ae-f0716a48e262"
      },
      "source": [
        "#You can write you answer here. (No code needed)\n",
        "\n",
        "K-means clustering is a clustering algorithm that divides sets of characteristics into k groups.  The total of the units of the length is collected by reducing them and the center cluster, and K is a positive integer. This clustering is the most used in today's market, and it calculates faster than any other clustering approach. However, the resultant clusters are dependent on the original randomly assigns, thus it does not always provide the same results. Simply put, K means reduces the variation in a cluster known as SSE (Sum of squared errors).  DBscan is a non-parametric clustering technique based on density.In the low-density zone, a collection of points are collected together that are densely packed, indicating outliers. Hierarchical clustering is an uncontrolled approach for producing consecutive grouping based on earlier defined clusters. Two are linked is a hierarchical clustering algorithm that divides each cluster into smaller ones before merging them into a bigger one. The items are clustered in this clustering algorithm depends on the difference between each cluster.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-81-f9826379d2e3>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    K-means clustering is a clustering algorithm that divides sets of characteristics into k groups.  The total of the units of the length is collected by reducing them and the center cluster, and K is a positive integer. This clustering is the most used in today's market, and it calculates faster than any other clustering approach. However, the resultant clusters are dependent on the original randomly assigns, thus it does not always provide the same results. Simply put, K means reduces the variation in a cluster known as SSE (Sum of squared errors).  DBscan is a non-parametric clustering technique based on density.In the low-density zone, a collection of points are collected together that are densely packed, indicating outliers. Hierarchical clustering is an uncontrolled approach for producing consecutive grouping based on earlier defined clusters. Two are linked is a hierarchical clustering algorithm that divides each cluster into smaller ones before merging them into a bigger one. The items are clustered in this clustering algorithm depends on the difference between each cluster.\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}